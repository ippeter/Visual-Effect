{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Parameters\n",
    "#\n",
    "SQUARE_SIZE = 5\n",
    "HEIGHT_SCALE = 16\n",
    "HEIGHT_WIDTH = 1\n",
    "BLACK_OFFSET = HEIGHT_WIDTH*HEIGHT_SCALE + SQUARE_SIZE\n",
    "\n",
    "#\n",
    "# Colors\n",
    "#\n",
    "clr_base_tile = 70\n",
    "clr_tile_border = 25\n",
    "clr_south_wall = 40\n",
    "clr_west_wall = 50\n",
    "\n",
    "#\n",
    "# Objects\n",
    "#\n",
    "obj_base_tile = np.zeros((SQUARE_SIZE, SQUARE_SIZE))\n",
    "obj_base_tile.fill(clr_base_tile)\n",
    "obj_base_tile[0, :] = clr_tile_border\n",
    "obj_base_tile[:, SQUARE_SIZE - 1] = clr_tile_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # initialize the face recognizer (default face haar cascade)\n",
    "    # download the XML file from here: https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "    face_cascade = cv2.CascadeClassifier(\"cascades/haarcascade_frontalface_alt.xml\")\n",
    "    \n",
    "    # detect all the faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    \n",
    "    # for every face, draw a blue rectangle\n",
    "    for x, y, width, height in faces:\n",
    "        #cv2.rectangle(gray, (x, y), (x + width, y + height), color=(255, 0, 0), thickness=2)\n",
    "        \n",
    "        # Get the face and show it\n",
    "        face = gray[y-BLACK_OFFSET:y+height+BLACK_OFFSET, x-BLACK_OFFSET:x+width+BLACK_OFFSET]\n",
    "        cv2.imshow(\"face\", face)\n",
    "    \n",
    "        # perform the canny edge detector to detect image edges and show them\n",
    "        #edges = cv2.Canny(face, threshold1=40, threshold2=75)\n",
    "        #cv2.imshow(\"edges\", edges)\n",
    "            \n",
    "        #\n",
    "        # Convert input black and white image to small picture and mean convolve\n",
    "        #\n",
    "        filter = np.zeros((SQUARE_SIZE, SQUARE_SIZE))\n",
    "        filter.fill(1.0 / SQUARE_SIZE**2)\n",
    "\n",
    "        small_img = sp.convolve2d(face, filter[::-1, ::-1], mode=\"valid\")[::SQUARE_SIZE, ::SQUARE_SIZE]\n",
    "        \n",
    "        #\n",
    "        # Scale the image of tiles\n",
    "        #\n",
    "        scaled_small_img = small_img - small_img.min()\n",
    "        scale = np.linspace(0, scaled_small_img.max(), HEIGHT_SCALE + 1)\n",
    "        scaled_small_img = np.digitize(scaled_small_img, scale) - 1\n",
    "        \n",
    "        #\n",
    "        # Main body of the effect\n",
    "        #\n",
    "\n",
    "        # This one makes the black border!\n",
    "        final_img = np.zeros((face.shape[0] + BLACK_OFFSET, face.shape[1] + BLACK_OFFSET)).astype(np.uint8)\n",
    "\n",
    "        # Actually fills the image with tiles and height\n",
    "        for ii in range(scaled_small_img.shape[0]):\n",
    "            for jj in range(scaled_small_img.shape[1] - 1, -1, -1):\n",
    "                height_value = int(scaled_small_img[ii, jj])\n",
    "\n",
    "                if (height_value > 0):\n",
    "                    left_lower_row = (ii + 1)*SQUARE_SIZE - 1 + BLACK_OFFSET\n",
    "                    left_lower_col = jj*SQUARE_SIZE\n",
    "\n",
    "                    for kk in range(0, height_value*HEIGHT_WIDTH):\n",
    "                        final_img[left_lower_row - kk, (left_lower_col + kk):(left_lower_col + SQUARE_SIZE + kk)] = clr_south_wall\n",
    "                        final_img[(left_lower_row - SQUARE_SIZE - kk + BLACK_OFFSET):(left_lower_row - kk - 1 + BLACK_OFFSET), left_lower_col + kk] = clr_west_wall\n",
    "\n",
    "                    final_img[(left_lower_row - SQUARE_SIZE - kk):(left_lower_row - kk), \n",
    "                              (left_lower_col + kk):(left_lower_col + SQUARE_SIZE + kk)] = obj_base_tile\n",
    "\n",
    "        # Show the result\n",
    "        cv2.imshow(\"Effect\", final_img)\n",
    "    \n",
    "    # show the image\n",
    "    cv2.imshow(\"image\", gray)\n",
    "    \n",
    "    if (cv2.waitKey(1) & 0xFF == ord(\"q\")):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
