{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "import dlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.pyplot import Polygon, Rectangle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initialize dlib modules\n",
    "#\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"./shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Parameters\n",
    "#\n",
    "SQUARE_SIZE = 5\n",
    "HEIGHT_SCALE = 16\n",
    "HEIGHT_WIDTH = 1\n",
    "BLACK_OFFSET = HEIGHT_WIDTH*HEIGHT_SCALE + SQUARE_SIZE\n",
    "\n",
    "#\n",
    "# Colors\n",
    "#\n",
    "clr_base_tile = 70\n",
    "clr_tile_border = 25\n",
    "clr_south_wall = 40\n",
    "clr_west_wall = 50\n",
    "\n",
    "#\n",
    "# Objects\n",
    "#\n",
    "obj_base_tile = np.zeros((SQUARE_SIZE, SQUARE_SIZE))\n",
    "obj_base_tile.fill(clr_base_tile)\n",
    "obj_base_tile[0, :] = clr_tile_border\n",
    "obj_base_tile[:, SQUARE_SIZE - 1] = clr_tile_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # initialize the face recognizer (default face haar cascade)\n",
    "    # download the XML file from here: https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "    #v1face_cascade = cv2.CascadeClassifier(\"cascades/haarcascade_frontalface_alt.xml\")\n",
    "    \n",
    "    # detect all the faces in the image\n",
    "    #v1faces = face_cascade.detectMultiScale(gray)\n",
    "    \n",
    "    faces = detector(gray, 1)\n",
    "\n",
    "    for k, d in enumerate(faces):\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = predictor(gray, d)\n",
    "        x1 = shape.part(0).x\n",
    "        y1 = shape.part(0).y\n",
    "        x2 = shape.part(16).x\n",
    "        y2 = shape.part(16).y\n",
    "        A = y2 - y1\n",
    "        B = -(x2 - x1)\n",
    "        C = -A*x1 - B*y1\n",
    "        M = np.sqrt(A**2 + B**2)    \n",
    "        AA = A / M\n",
    "        BB = B / M\n",
    "        CC = C / M\n",
    "\n",
    "        coords = np.zeros((32, 2)).astype(np.int32)\n",
    "\n",
    "        for ii in range(17):\n",
    "            coords[ii, :] = (shape.part(ii).x, shape.part(ii).y)\n",
    "\n",
    "        for ii in range(15, 0, -1):\n",
    "            px = shape.part(ii).x\n",
    "            py = shape.part(ii).y\n",
    "\n",
    "            D = AA * px + BB * py + CC\n",
    "            pxx = int(px - 2*AA*D)\n",
    "            pyy = int(py - 2*BB*D)\n",
    "\n",
    "            coords[32 - ii, :] = (pxx, pyy)\n",
    "\n",
    "        # Face box\n",
    "        XUL = min(coords, key = lambda x: x[0])[0] - 20\n",
    "        YUL = min(coords, key = lambda x: x[1])[1] - 20\n",
    "        XLR = max(coords, key = lambda x: x[0])[0] + 20\n",
    "        YLR = max(coords, key = lambda x: x[1])[1] + 20\n",
    "\n",
    "        facebox = Rectangle((XUL, YUL), width=(XLR - XUL), height=(YLR - YUL), fill=False)\n",
    "        face = gray[YUL:YLR, XUL:XLR]\n",
    "\n",
    "    coords[:, 0] = coords[:, 0] - XUL\n",
    "    coords[:, 1] = coords[:, 1] - YUL\n",
    "    \n",
    "    stencil = np.zeros(face.shape).astype(face.dtype)\n",
    "    cv2.fillPoly(stencil, [coords], 255)\n",
    "    result = np.bitwise_and(face, stencil)\n",
    "    \n",
    "    #\n",
    "    # Convert input black and white image to small picture and mean convolve\n",
    "    #\n",
    "    filter = np.zeros((SQUARE_SIZE, SQUARE_SIZE))\n",
    "    filter.fill(1.0 / SQUARE_SIZE**2)\n",
    "\n",
    "    small_img = sp.convolve2d(result, filter[::-1, ::-1], mode=\"valid\")[::SQUARE_SIZE, ::SQUARE_SIZE]\n",
    "\n",
    "    #\n",
    "    # Scale the image of tiles\n",
    "    #\n",
    "    scaled_small_img = small_img - small_img.min()\n",
    "    scale = np.linspace(0, scaled_small_img.max(), HEIGHT_SCALE + 1)\n",
    "    scaled_small_img = np.digitize(scaled_small_img, scale) - 1\n",
    "\n",
    "    #\n",
    "    # Main body of the effect\n",
    "    #\n",
    "\n",
    "    # This one makes the black border!\n",
    "    final_img = np.zeros((face.shape[0] + BLACK_OFFSET, face.shape[1] + BLACK_OFFSET)).astype(np.uint8)\n",
    "\n",
    "    # Actually fills the image with tiles and height\n",
    "    for ii in range(scaled_small_img.shape[0]):\n",
    "        for jj in range(scaled_small_img.shape[1] - 1, -1, -1):\n",
    "            height_value = int(scaled_small_img[ii, jj])\n",
    "\n",
    "            if (height_value > 0):\n",
    "                left_lower_row = (ii + 1)*SQUARE_SIZE - 1 + BLACK_OFFSET\n",
    "                left_lower_col = jj*SQUARE_SIZE\n",
    "\n",
    "                for kk in range(0, height_value*HEIGHT_WIDTH):\n",
    "                    final_img[left_lower_row - kk, (left_lower_col + kk):(left_lower_col + SQUARE_SIZE + kk)] = clr_south_wall\n",
    "                    final_img[(left_lower_row - SQUARE_SIZE - kk + BLACK_OFFSET):(left_lower_row - kk - 1 + BLACK_OFFSET), left_lower_col + kk] = clr_west_wall\n",
    "\n",
    "                final_img[(left_lower_row - SQUARE_SIZE - kk):(left_lower_row - kk), \n",
    "                          (left_lower_col + kk):(left_lower_col + SQUARE_SIZE + kk)] = obj_base_tile\n",
    "\n",
    "    \n",
    "    # Sow everything\n",
    "    cv2.imshow(\"image\", gray)\n",
    "    cv2.imshow(\"face\", face)\n",
    "    cv2.imshow(\"result\", result)\n",
    "    cv2.imshow(\"Effect\", final_img)\n",
    "    \n",
    "    if (cv2.waitKey(1) & 0xFF == ord(\"q\")):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
